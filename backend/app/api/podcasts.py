"""
Podcast API è·¯ç”±
"""
from fastapi import APIRouter, File, UploadFile, HTTPException, status, Query
from fastapi.responses import StreamingResponse
from typing import Optional, List
import uuid
from pathlib import Path
import io

from app.schemas.podcast import UploadResponse, ApiResponse, PodcastResponse, GenerateRequest, AnalyzeAndGenerateRequest, YouTubeGenerateRequest
from app.services.data_service import data_service
from app.utils.s3_storage import s3_storage
from app.config import settings

router = APIRouter(prefix="/api/v1/podcasts", tags=["podcasts"])


def validate_file(file: UploadFile) -> tuple[bool, Optional[str]]:
    """
    éªŒè¯ä¸Šä¼ æ–‡ä»¶
    
    Returns:
        (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯æ¶ˆæ¯)
    """
    # æ£€æŸ¥æ–‡ä»¶å
    if not file.filename:
        return False, "æ–‡ä»¶åä¸èƒ½ä¸ºç©º"
    
    # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
    file_ext = Path(file.filename).suffix.lower()
    if file_ext not in settings.allowed_extensions:
        return False, f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}ã€‚æ”¯æŒçš„ç±»å‹: {', '.join(settings.allowed_extensions)}"
    
    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    file.file.seek(0, 2)  # ç§»åŠ¨åˆ°æ–‡ä»¶æœ«å°¾
    file_size = file.file.tell()
    file.file.seek(0)  # é‡ç½®åˆ°å¼€å¤´
    
    if file_size > settings.max_upload_size:
        max_size_mb = settings.max_upload_size / (1024 * 1024)
        return False, f"æ–‡ä»¶è¿‡å¤§: {file_size / (1024 * 1024):.2f}MBã€‚æœ€å¤§å…è®¸: {max_size_mb}MB"
    
    if file_size == 0:
        return False, "æ–‡ä»¶ä¸ºç©º"
    
    return True, None


@router.post("/upload", response_model=UploadResponse)
async def upload_file(file: UploadFile = File(...)):
    """
    ä¸Šä¼ æ–‡ä»¶åˆ›å»ºæ’­å®¢
    
    1. éªŒè¯æ–‡ä»¶ï¼ˆç±»å‹ã€å¤§å°ï¼‰
    2. ä¸Šä¼ åˆ° S3
    3. åˆ›å»º podcast å’Œ job è®°å½•
    4. è¿”å› podcast_id å’Œ job_id
    """
    # 1. éªŒè¯æ–‡ä»¶
    is_valid, error_msg = validate_file(file)
    if not is_valid:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=error_msg
        )
    
    try:
        # 2. ä¸Šä¼ æ–‡ä»¶åˆ° S3
        file_content = await file.read()
        
        # é‡æ–°åŒ…è£…ä¸º BytesIO å¯¹è±¡
        import io
        file_obj = io.BytesIO(file_content)
        
        s3_key = s3_storage.upload_file(
            file_obj=file_obj,
            original_filename=file.filename,
            prefix="uploads",
            content_type=file.content_type
        )
        
        if not s3_key:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="æ–‡ä»¶ä¸Šä¼ åˆ° S3 å¤±è´¥"
            )
        
        # 3. åˆ›å»º podcast å’Œ job è®°å½•
        podcast_id = str(uuid.uuid4())
        job_id = str(uuid.uuid4())
        
        # ç¡®å®šæ–‡ä»¶ç±»å‹
        file_type = "text"  # é»˜è®¤æ˜¯æ–‡æœ¬/æ–‡æ¡£
        if file.content_type:
            if file.content_type.startswith("audio/"):
                file_type = "audio"
            elif file.content_type.startswith("video/"):
                file_type = "video"
        
        # ä¿å­˜ podcast è®°å½•
        podcast_data = {
            "id": podcast_id,
            "title": file.filename,  # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºæ ‡é¢˜
            "original_filename": file.filename,
            "s3_key": s3_key,
            "file_size_bytes": len(file_content),
            "status": "processing",
            # æ–°å¢å­—æ®µï¼šæ”¯æŒå¤šç§å†…å®¹æº
            "source_type": file_type,
            "source_url": None,
            "extraction_metadata": None,
            "original_duration": None,
            "original_format": file.filename.split('.')[-1].lower() if '.' in file.filename else None
        }
        
        success = data_service.save_podcast(podcast_data)
        if not success:
            # å›æ»š S3 ä¸Šä¼ 
            s3_storage.delete_file(s3_key)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="ä¿å­˜æ’­å®¢è®°å½•å¤±è´¥"
            )
        
        # ä¿å­˜ job è®°å½•
        job_data = {
            "id": job_id,
            "podcast_id": podcast_id,
            "status": "pending",
            "progress": 0,
            "s3_key": s3_key
        }
        
        success = data_service.save_job(job_data)
        if not success:
            # å›æ»š
            data_service.delete_podcast(podcast_id)
            s3_storage.delete_file(s3_key)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="ä¿å­˜ä»»åŠ¡è®°å½•å¤±è´¥"
            )
        
        # 4. å¯åŠ¨åå°å¤„ç†
        from app.tasks.process_podcast import start_processing_task
        start_processing_task(podcast_id, job_id, s3_key)
        
        # 5. è¿”å›å“åº”
        return UploadResponse(
            podcast_id=podcast_id,
            job_id=job_id,
            status="processing",
            message=f"æ–‡ä»¶ '{file.filename}' ä¸Šä¼ æˆåŠŸï¼Œæ­£åœ¨å¤„ç†ä¸­"
        )
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ ä¸Šä¼ å¼‚å¸¸: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}"
        )


@router.get("", response_model=List[PodcastResponse])
async def get_podcasts(
    page: int = Query(1, ge=1, description="é¡µç "),
    limit: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    search: Optional[str] = Query(None, description="æœç´¢æ ‡é¢˜")
):
    """
    è·å–æ’­å®¢åˆ—è¡¨
    
    - **page**: é¡µç ï¼ˆä»1å¼€å§‹ï¼‰
    - **limit**: æ¯é¡µæ•°é‡ï¼ˆ1-100ï¼‰
    - **search**: æœç´¢å…³é”®è¯ï¼ˆåŒ¹é…æ ‡é¢˜ï¼‰
    """
    from fastapi.responses import JSONResponse
    
    try:
        # è¯»å–æ‰€æœ‰æ’­å®¢
        all_podcasts = data_service.read_podcasts()
        
        # æœç´¢è¿‡æ»¤
        if search:
            search_lower = search.lower()
            all_podcasts = [
                p for p in all_podcasts 
                if search_lower in p.get("title", "").lower()
            ]
        
        # æ’åºï¼šæŒ‰åˆ›å»ºæ—¶é—´é™åº
        all_podcasts.sort(
            key=lambda x: x.get("created_at", ""),
            reverse=True
        )
        
        # åˆ†é¡µ
        start = (page - 1) * limit
        end = start + limit
        podcasts = all_podcasts[start:end]
        
        # ä¸ºæ¯ä¸ªæ’­å®¢è®¾ç½®æµå¼æ’­æ”¾ URL
        from app.config import settings
        for podcast in podcasts:
            if podcast.get("audio_s3_key"):
                # ä½¿ç”¨å®Œæ•´çš„åç«¯æµå¼æ’­æ”¾ URLï¼ˆæ”¯æŒ Vercel ç­‰è·¨åŸŸéƒ¨ç½²ï¼‰
                podcast["audio_url"] = f"{settings.api_domain}/api/v1/podcasts/{podcast['id']}/stream"
        
        # è¿”å›å¸¦ç¼“å­˜æ§åˆ¶å¤´çš„å“åº”ï¼Œé¿å…æµè§ˆå™¨ç¼“å­˜åŠ¨æ€å†…å®¹
        return JSONResponse(
            content=podcasts,
            headers={
                "Cache-Control": "no-cache, no-store, must-revalidate",
                "Pragma": "no-cache",
                "Expires": "0"
            }
        )
    
    except Exception as e:
        print(f"âŒ è·å–æ’­å®¢åˆ—è¡¨å¼‚å¸¸: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–æ’­å®¢åˆ—è¡¨å¤±è´¥: {str(e)}"
        )


@router.get("/{podcast_id}", response_model=PodcastResponse)
async def get_podcast(podcast_id: str):
    """
    è·å–æ’­å®¢è¯¦æƒ…
    
    - **podcast_id**: æ’­å®¢ID
    """
    from fastapi.responses import JSONResponse
    
    podcast = data_service.get_podcast(podcast_id)
    
    if not podcast:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"æ’­å®¢ä¸å­˜åœ¨: {podcast_id}"
        )
    
    # å¦‚æœæœ‰éŸ³é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨æµå¼æ’­æ”¾ URL
    if podcast.get("audio_s3_key"):
        # ä½¿ç”¨å®Œæ•´çš„åç«¯æµå¼æ’­æ”¾ URLï¼ˆæ”¯æŒ Vercel ç­‰è·¨åŸŸéƒ¨ç½²ï¼‰
        from app.config import settings
        podcast["audio_url"] = f"{settings.api_domain}/api/v1/podcasts/{podcast_id}/stream"
    
    # è¿”å›å¸¦ç¼“å­˜æ§åˆ¶å¤´çš„å“åº”ï¼Œé¿å…æµè§ˆå™¨ç¼“å­˜åŠ¨æ€å†…å®¹
    return JSONResponse(
        content=podcast,
        headers={
            "Cache-Control": "no-cache, no-store, must-revalidate",
            "Pragma": "no-cache",
            "Expires": "0"
        }
    )


@router.delete("/{podcast_id}")
async def delete_podcast(podcast_id: str):
    """
    åˆ é™¤æ’­å®¢
    
    - **podcast_id**: æ’­å®¢ID
    """
    try:
        # è·å–æ’­å®¢ä¿¡æ¯
        podcast = data_service.get_podcast(podcast_id)
        
        if not podcast:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"æ’­å®¢ä¸å­˜åœ¨: {podcast_id}"
            )
        
        # åˆ é™¤ S3 æ–‡ä»¶
        s3_key = podcast.get("s3_key")
        if s3_key:
            s3_storage.delete_file(s3_key)
        
        # åˆ é™¤éŸ³é¢‘æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        audio_s3_key = podcast.get("audio_s3_key")
        if audio_s3_key:
            s3_storage.delete_file(audio_s3_key)
        
        # åˆ é™¤æ•°æ®åº“è®°å½•
        success = data_service.delete_podcast(podcast_id)
        
        if not success:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="åˆ é™¤æ’­å®¢è®°å½•å¤±è´¥"
            )
        
        return {
            "success": True,
            "message": f"æ’­å®¢ '{podcast.get('title')}' å·²åˆ é™¤"
        }
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ åˆ é™¤æ’­å®¢å¼‚å¸¸: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ é™¤æ’­å®¢å¤±è´¥: {str(e)}"
        )


@router.get("/{podcast_id}/download")
async def download_podcast(podcast_id: str):
    """
    è·å–æ’­å®¢ä¸‹è½½é“¾æ¥
    
    - **podcast_id**: æ’­å®¢ID
    
    è¿”å›é¢„ç­¾åä¸‹è½½ URLï¼ˆæœ‰æ•ˆæœŸ1å°æ—¶ï¼‰
    """
    try:
        # è·å–æ’­å®¢ä¿¡æ¯
        podcast = data_service.get_podcast(podcast_id)
        
        if not podcast:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"æ’­å®¢ä¸å­˜åœ¨: {podcast_id}"
            )
        
        # æ£€æŸ¥éŸ³é¢‘æ˜¯å¦å·²ç”Ÿæˆ
        audio_s3_key = podcast.get("audio_s3_key")
        if not audio_s3_key:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="æ’­å®¢éŸ³é¢‘å°šæœªç”Ÿæˆï¼Œè¯·ç¨åå†è¯•"
            )
        
        # ç”Ÿæˆé¢„ç­¾å URLï¼ˆ1å°æ—¶æœ‰æ•ˆæœŸï¼‰ï¼Œå¼ºåˆ¶ä¸‹è½½
        filename = f"{podcast.get('title', 'podcast')}.mp3"
        download_url = s3_storage.generate_presigned_url(
            audio_s3_key,
            expires_in=3600,
            filename=filename,
            force_download=True
        )
        
        if not download_url:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="ç”Ÿæˆä¸‹è½½é“¾æ¥å¤±è´¥"
            )
        
        return {
            "success": True,
            "download_url": download_url,
            "expires_in": 3600,
            "filename": filename
        }
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ è·å–ä¸‹è½½é“¾æ¥å¼‚å¸¸: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ä¸‹è½½é“¾æ¥å¤±è´¥: {str(e)}"
        )


@router.get("/{podcast_id}/stream")
async def stream_podcast(podcast_id: str):
    """
    æµå¼æ’­æ”¾æ’­å®¢éŸ³é¢‘
    
    - **podcast_id**: æ’­å®¢ID
    
    ç›´æ¥ä» S3 æµå¼ä¼ è¾“éŸ³é¢‘æ•°æ®
    """
    try:
        # è·å–æ’­å®¢ä¿¡æ¯
        podcast = data_service.get_podcast(podcast_id)
        
        if not podcast:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"æ’­å®¢ä¸å­˜åœ¨: {podcast_id}"
            )
        
        # æ£€æŸ¥éŸ³é¢‘æ˜¯å¦å·²ç”Ÿæˆ
        audio_s3_key = podcast.get("audio_s3_key")
        if not audio_s3_key:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="æ’­å®¢éŸ³é¢‘å°šæœªç”Ÿæˆï¼Œè¯·ç¨åå†è¯•"
            )
        
        # ä» S3 ä¸‹è½½éŸ³é¢‘æ•°æ®
        audio_data = s3_storage.download_file(audio_s3_key)
        if not audio_data:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="éŸ³é¢‘æ–‡ä»¶ä¸‹è½½å¤±è´¥"
            )
        
        # å¯¹æ–‡ä»¶åè¿›è¡ŒURLç¼–ç ä»¥æ”¯æŒä¸­æ–‡
        from urllib.parse import quote
        from io import BytesIO
        
        filename = podcast.get('title', 'podcast')
        encoded_filename = quote(filename)
        
        # ä½¿ç”¨ BytesIO åŒ…è£…éŸ³é¢‘æ•°æ®ï¼Œç¡®ä¿å¯ä»¥è¢«å¤šæ¬¡è¯»å–
        # å¹¶æ·»åŠ  Content-Length å¤´è®©æµè§ˆå™¨çŸ¥é“éŸ³é¢‘æ€»é•¿åº¦
        return StreamingResponse(
            BytesIO(audio_data),
            media_type="audio/mpeg",
            headers={
                "Content-Disposition": f"inline; filename*=UTF-8''{encoded_filename}.mp3",
                "Content-Length": str(len(audio_data)),
                "Accept-Ranges": "bytes",
                "Cache-Control": "public, max-age=3600"
            }
        )
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ æµå¼æ’­æ”¾å¼‚å¸¸: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æµå¼æ’­æ”¾å¤±è´¥: {str(e)}"
        )


@router.post("/generate", response_model=UploadResponse)
async def generate_podcast(request: GenerateRequest):
    """
    ä½¿ç”¨ AI ç”Ÿæˆæ’­å®¢
    
    æ ¹æ®ç”¨æˆ·æä¾›çš„ä¸»é¢˜å’Œé£æ ¼ï¼Œä½¿ç”¨ Gemini AI ç”Ÿæˆæ’­å®¢ç¨¿ä»¶ï¼Œ
    ç„¶åä½¿ç”¨ ElevenLabs TTS ç”ŸæˆéŸ³é¢‘
    
    - **topic**: æ’­å®¢ä¸»é¢˜ (5-500å­—ç¬¦)
    - **style**: æ’­å®¢é£æ ¼ (å•äººè„±å£ç§€/åŒäººå¯¹è¯/æ•…äº‹å™è¿°)
    - **duration_minutes**: ç›®æ ‡æ—¶é•¿ (3-15åˆ†é’Ÿ)
    """
    try:
        # 1. åˆ›å»º podcast å’Œ job è®°å½•
        podcast_id = str(uuid.uuid4())
        job_id = str(uuid.uuid4())
        
        # ä½¿ç”¨ä¸»é¢˜ä½œä¸ºæ ‡é¢˜ï¼ˆæˆªå–å‰50å­—ç¬¦ï¼‰
        title = request.topic[:50] + ("..." if len(request.topic) > 50 else "")
        
        # ä¿å­˜ podcast è®°å½•
        podcast_data = {
            "id": podcast_id,
            "title": title,
            "original_filename": f"AIç”Ÿæˆ-{request.style}",
            "status": "processing",
            # æ–°å¢å­—æ®µï¼šæ”¯æŒå¤šç§å†…å®¹æº
            "source_type": "text",  # AI æ–‡æœ¬ç”Ÿæˆ
            "source_url": None,
            "extraction_metadata": {"topic": request.topic, "style": request.style},
            "original_duration": None,
            "original_format": "ai_generated"
        }
        
        success = data_service.save_podcast(podcast_data)
        if not success:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="ä¿å­˜æ’­å®¢è®°å½•å¤±è´¥"
            )
        
        # ä¿å­˜ job è®°å½•ï¼ˆåŒ…å« type å’Œ inputsï¼‰
        job_data = {
            "id": job_id,
            "podcast_id": podcast_id,
            "type": "generate",  # æ ‡è®°ä¸º AI ç”Ÿæˆç±»å‹
            "inputs": {
                "topic": request.topic,
                "style": request.style,
                "duration_minutes": request.duration_minutes,
                "language": request.language
            },
            "status": "pending",
            "progress": 0
        }
        
        success = data_service.save_job(job_data)
        if not success:
            # å›æ»š
            data_service.delete_podcast(podcast_id)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="ä¿å­˜ä»»åŠ¡è®°å½•å¤±è´¥"
            )
        
        # 2. å¯åŠ¨åå° AI ç”Ÿæˆä»»åŠ¡
        from app.tasks.process_podcast import start_processing_task
        start_processing_task(podcast_id, job_id, None)  # s3_key ä¸º Noneï¼ˆæ— éœ€ä¸‹è½½æ–‡ä»¶ï¼‰
        
        # 3. è¿”å›å“åº”
        return UploadResponse(
            podcast_id=podcast_id,
            job_id=job_id,
            status="processing",
            message=f"æ­£åœ¨ç”Ÿæˆæ’­å®¢ï¼š{title}"
        )
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ AIç”Ÿæˆæ’­å®¢å¼‚å¸¸: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"AIç”Ÿæˆæ’­å®¢å¤±è´¥: {str(e)}"
        )



@router.post("/analyze-and-generate-direct", response_model=UploadResponse)
async def analyze_and_generate_direct(
    file: UploadFile = File(...),
    style: str = Query("Conversation", description="æ’­å®¢é£æ ¼"),
    duration_minutes: int = Query(5, ge=3, le=15, description="ç›®æ ‡æ—¶é•¿"),
    language: str = Query("en", description="æ’­å®¢è¯­è¨€"),
    enhancement_prompt: str = Query("", description="å¢å¼ºæç¤º")
):
    """
    ç›´æ¥ä¸Šä¼ éŸ³é¢‘/è§†é¢‘æ–‡ä»¶å¹¶åˆ†æç”Ÿæˆæ’­å®¢ï¼ˆæ¨èä½¿ç”¨ï¼‰
    
    ä¸€æ­¥å®Œæˆï¼šä¸Šä¼ æ–‡ä»¶ + AIåˆ†æ + ç”Ÿæˆæ’­å®¢ï¼Œä¸ä¼šåœ¨libraryä¸­ç•™ä¸‹ä¸´æ—¶è®°å½•
    
    - **file**: éŸ³é¢‘æˆ–è§†é¢‘æ–‡ä»¶
    - **style**: æ’­å®¢é£æ ¼ï¼ˆConversation/Storytelling/Soloï¼‰
    - **duration_minutes**: ç›®æ ‡æ—¶é•¿ï¼ˆ3-15åˆ†é’Ÿï¼‰
    - **language**: æ’­å®¢è¯­è¨€ï¼ˆen/zhï¼‰
    - **enhancement_prompt**: å¯é€‰çš„å¢å¼ºæç¤º
    """
    try:
        # 1. éªŒè¯æ–‡ä»¶
        is_valid, error_msg = validate_file(file)
        if not is_valid:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=error_msg
            )
        
        # 2. ä¸Šä¼ æ–‡ä»¶åˆ° S3ï¼ˆä¸´æ—¶å­˜å‚¨ï¼‰
        file_content = await file.read()
        file_obj = io.BytesIO(file_content)
        
        s3_key = s3_storage.upload_file(
            file_obj=file_obj,
            original_filename=file.filename,
            prefix="uploads",
            content_type=file.content_type
        )
        
        if not s3_key:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="æ–‡ä»¶ä¸Šä¼ åˆ° S3 å¤±è´¥"
            )
        
        # 3. ç¡®å®šæ–‡ä»¶ç±»å‹
        source_type = "video" if file.content_type.startswith("video/") else "audio"
        
        # 4. åˆ›å»º podcast å’Œ job è®°å½•
        podcast_id = str(uuid.uuid4())
        job_id = str(uuid.uuid4())
        
        # ä½¿ç”¨ä¸´æ—¶æ ‡é¢˜ï¼ˆä¼šåœ¨å¤„ç†åæ›´æ–°ä¸ºAIç”Ÿæˆçš„æ ‡é¢˜ï¼‰
        title = f"Processing: {file.filename[:40]}..."
        
        podcast_data = {
            "id": podcast_id,
            "title": title,
            "original_filename": file.filename,
            "status": "processing",
            # æ–°å¢å­—æ®µï¼šæ”¯æŒå¤šç§å†…å®¹æº
            "source_type": source_type,  # "audio" æˆ– "video"
            "source_url": None,  # æ–‡ä»¶ä¸Šä¼ æ²¡æœ‰ URL
            "extraction_metadata": None,  # å°†åœ¨å¤„ç†åå¡«å……
            "original_duration": None,  # å°†åœ¨å¤„ç†åå¡«å……
            "original_format": file.filename.split('.')[-1].lower() if '.' in file.filename else None
        }
        
        success = data_service.save_podcast(podcast_data)
        if not success:
            s3_storage.delete_file(s3_key)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="ä¿å­˜æ’­å®¢è®°å½•å¤±è´¥"
            )
        
        # 5. åˆ›å»ºä»»åŠ¡è®°å½•
        job_data = {
            "id": job_id,
            "podcast_id": podcast_id,
            "type": "analyze_generate",
            "inputs": {
                "file_s3_key": s3_key,
                "source_type": source_type,
                "enhancement_prompt": enhancement_prompt,
                "style": style,
                "duration_minutes": duration_minutes,
                "language": language
            },
            "status": "pending",
            "progress": 0
        }
        
        success = data_service.save_job(job_data)
        if not success:
            data_service.delete_podcast(podcast_id)
            s3_storage.delete_file(s3_key)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="ä¿å­˜ä»»åŠ¡è®°å½•å¤±è´¥"
            )
        
        # 6. å¯åŠ¨åå°åˆ†æå’Œç”Ÿæˆä»»åŠ¡
        from app.tasks.process_podcast import start_analyze_generate_task
        start_analyze_generate_task(podcast_id, job_id, s3_key)
        
        return UploadResponse(
            podcast_id=podcast_id,
            job_id=job_id,
            status="processing",
            message=f"æ­£åœ¨åˆ†æå¹¶ç”Ÿæˆæ’­å®¢ï¼š{file.filename}"
        )
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ ç›´æ¥åˆ†æç”Ÿæˆå¤±è´¥: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å¤„ç†å¤±è´¥: {str(e)}"
        )


@router.post("/analyze-and-generate", response_model=UploadResponse)
async def analyze_and_generate_podcast(request: AnalyzeAndGenerateRequest):
    """
    ä»éŸ³é¢‘/è§†é¢‘æ–‡ä»¶åˆ†æå¹¶ç”Ÿæˆæ’­å®¢ï¼ˆæ—§æ¥å£ï¼Œéœ€è¦å…ˆä¸Šä¼ è·å–S3 keyï¼‰
    
    ä»å·²ä¸Šä¼ çš„éŸ³é¢‘/è§†é¢‘æ–‡ä»¶ä¸­æå–å†…å®¹ï¼Œåˆ†æåç”Ÿæˆæ–°çš„æ’­å®¢ã€‚
    è¯¥ç«¯ç‚¹ç»“åˆäº†å†…å®¹åˆ†æå’Œ AI ç”ŸæˆåŠŸèƒ½ã€‚
    
    æ¨èä½¿ç”¨ /analyze-and-generate-direct ç›´æ¥ä¸Šä¼ æ–‡ä»¶
    
    - **file_s3_key**: å·²ä¸Šä¼ æ–‡ä»¶çš„ S3 key
    - **enhancement_prompt**: å¯é€‰çš„å¢å¼ºæç¤ºï¼ˆæŒ‡å¯¼ AI å…³æ³¨ç‰¹å®šæ–¹é¢ï¼‰
    - **source_type**: æºæ–‡ä»¶ç±»å‹ï¼ˆaudio æˆ– videoï¼‰
    - **style**: æ’­å®¢é£æ ¼ï¼ˆå•äººè„±å£ç§€/åŒäººå¯¹è¯/æ•…äº‹å™è¿°ï¼‰
    - **duration_minutes**: ç›®æ ‡æ—¶é•¿ï¼ˆ3-15åˆ†é’Ÿï¼‰
    - **language**: æ’­å®¢è¯­è¨€ï¼ˆen/zhï¼‰
    """
    try:
        # 1. éªŒè¯ S3 key å­˜åœ¨
        print(f"ğŸ¬ å¼€å§‹ä»æ–‡ä»¶ç”Ÿæˆæ’­å®¢...")
        print(f"   S3 Key: {request.file_s3_key}")
        print(f"   æºç±»å‹: {request.source_type}")
        
        # éªŒè¯æºç±»å‹
        if request.source_type not in ["audio", "video"]:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="æºç±»å‹å¿…é¡»æ˜¯ 'audio' æˆ– 'video'"
            )
        
        # 2. åˆ›å»º podcast å’Œ job è®°å½•
        podcast_id = str(uuid.uuid4())
        job_id = str(uuid.uuid4())
        
        # ä» S3 key ä¸­æå–åŸå§‹æ–‡ä»¶å
        original_filename = Path(request.file_s3_key).name
        title = f"AIåˆ†æ-{original_filename[:30]}..."
        
        # ä¿å­˜ podcast è®°å½•
        podcast_data = {
            "id": podcast_id,
            "title": title,
            "original_filename": original_filename,
            "status": "processing"
        }
        
        success = data_service.save_podcast(podcast_data)
        if not success:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="ä¿å­˜æ’­å®¢è®°å½•å¤±è´¥"
            )
        
        # ä¿å­˜ job è®°å½•ï¼ˆåŒ…å« type å’Œ inputsï¼‰
        job_data = {
            "id": job_id,
            "podcast_id": podcast_id,
            "type": "analyze_generate",  # æ–°ç±»å‹ï¼šåˆ†æå¹¶ç”Ÿæˆ
            "inputs": {
                "file_s3_key": request.file_s3_key,
                "source_type": request.source_type,
                "enhancement_prompt": request.enhancement_prompt,
                "style": request.style,
                "duration_minutes": request.duration_minutes,
                "language": request.language
            },
            "status": "pending",
            "progress": 0
        }
        
        success = data_service.save_job(job_data)
        if not success:
            # å›æ»š
            data_service.delete_podcast(podcast_id)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="ä¿å­˜ä»»åŠ¡è®°å½•å¤±è´¥"
            )
        
        # 3. å¯åŠ¨åå°åˆ†æå’Œç”Ÿæˆä»»åŠ¡
        from app.tasks.process_podcast import start_analyze_generate_task
        start_analyze_generate_task(podcast_id, job_id, request.file_s3_key)
        
        # 4. è¿”å›å“åº”
        return UploadResponse(
            podcast_id=podcast_id,
            job_id=job_id,
            status="processing",
            message=f"æ­£åœ¨åˆ†æå¹¶ç”Ÿæˆæ’­å®¢ï¼š{title}"
        )
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ åˆ†æç”Ÿæˆæ’­å®¢å¼‚å¸¸: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"åˆ†æç”Ÿæˆæ’­å®¢å¤±è´¥: {str(e)}"
        )


@router.post("/generate-from-youtube", response_model=UploadResponse)
async def generate_from_youtube(request: YouTubeGenerateRequest):
    """
    ä» YouTube è§†é¢‘ç”Ÿæˆæ’­å®¢
    
    æå– YouTube è§†é¢‘çš„å­—å¹•æˆ–éŸ³é¢‘å†…å®¹ï¼Œç„¶åä½¿ç”¨ AI ç”Ÿæˆæ’­å®¢
    
    - **youtube_url**: YouTube è§†é¢‘é“¾æ¥
    - **language**: æ’­å®¢è¯­è¨€ (en/zh)
    - **enhancement_prompt**: å¯é€‰çš„å¢å¼ºæç¤º
    - **style**: æ’­å®¢é£æ ¼ (Conversation/Storytelling/Solo)
    - **duration_minutes**: ç›®æ ‡æ—¶é•¿ï¼ˆ3-15åˆ†é’Ÿï¼‰
    """
    try:
        # 1. éªŒè¯ YouTube URL
        from app.services.youtube_extractor import youtube_extractor
        
        is_valid, error_msg = youtube_extractor.validate_url(request.youtube_url)
        if not is_valid:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=error_msg
            )
        
        # 2. è·å–è§†é¢‘å…ƒæ•°æ®
        try:
            metadata = youtube_extractor.extract_metadata(request.youtube_url)
        except Exception as e:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"æ— æ³•è®¿é—® YouTube è§†é¢‘: {str(e)}"
            )
        
        # 3. åˆ›å»º podcast å’Œ job è®°å½•
        podcast_id = str(uuid.uuid4())
        job_id = str(uuid.uuid4())
        
        # ä½¿ç”¨ YouTube è§†é¢‘æ ‡é¢˜ä½œä¸ºæ’­å®¢æ ‡é¢˜
        title = f"Processing: {metadata['title'][:50]}..."
        
        podcast_data = {
            "id": podcast_id,
            "title": title,
            "original_filename": f"YouTube-{metadata['video_id']}",
            "status": "processing",
            # æ–°å¢å­—æ®µï¼šYouTube æ¥æº
            "source_type": "youtube",
            "source_url": request.youtube_url,
            "extraction_metadata": {
                "youtube_title": metadata['title'],
                "youtube_uploader": metadata['uploader'],
                "youtube_duration": metadata['duration']
            },
            "original_duration": float(metadata['duration']),
            "original_format": "youtube"
        }
        
        success = data_service.save_podcast(podcast_data)
        if not success:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="ä¿å­˜æ’­å®¢è®°å½•å¤±è´¥"
            )
        
        # 4. åˆ›å»ºä»»åŠ¡è®°å½•
        job_data = {
            "id": job_id,
            "podcast_id": podcast_id,
            "type": "youtube_generate",
            "inputs": {
                "youtube_url": request.youtube_url,
                "youtube_metadata": metadata,
                "enhancement_prompt": request.enhancement_prompt,
                "style": request.style,
                "duration_minutes": request.duration_minutes,
                "language": request.language
            },
            "status": "pending",
            "progress": 0
        }
        
        success = data_service.save_job(job_data)
        if not success:
            data_service.delete_podcast(podcast_id)
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="ä¿å­˜ä»»åŠ¡è®°å½•å¤±è´¥"
            )
        
        # 5. å¯åŠ¨åå° YouTube ç”Ÿæˆä»»åŠ¡
        from app.tasks.process_podcast import start_youtube_generate_task
        start_youtube_generate_task(podcast_id, job_id, request.youtube_url)
        
        return UploadResponse(
            podcast_id=podcast_id,
            job_id=job_id,
            status="processing",
            message=f"YouTube è§†é¢‘åˆ†æå·²å¼€å§‹ï¼š{metadata['title']}"
        )
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"Error in generate_from_youtube: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ç”Ÿæˆæ’­å®¢å¤±è´¥: {str(e)}"
        )
